import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import time

# --- Page Configuration ---
st.set_page_config(
    page_title="Dashboard de Optimizaci贸n de Despacho de Ambulancias",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Data Caching and Generation ---
@st.cache_data
def cargar_datos():
    """
    Genera datos simulados realistas restringidos al 谩rea de Tijuana, M茅xico.
    """
    lat_min, lat_max = 32.40, 32.55
    lon_min, lon_max = -117.12, -116.60
    num_llamadas = 500
    np.random.seed(42)
    latitudes = np.random.uniform(lat_min, lat_max, num_llamadas)
    longitudes = np.random.uniform(lon_min, lon_max, num_llamadas)
    tiempo_api = np.random.uniform(5, 30, num_llamadas)
    tiempo_real = tiempo_api * np.random.uniform(0.6, 0.95, num_llamadas)
    tiempo_corregido = tiempo_real * np.random.uniform(0.95, 1.05, num_llamadas)
    df_llamadas = pd.DataFrame({
        'lat': latitudes, 'lon': longitudes, 'tiempo_api_minutos': tiempo_api,
        'tiempo_real_minutos': tiempo_real, 'tiempo_corregido_minutos': tiempo_corregido
    })
    bases_actuales = pd.DataFrame({
        'nombre': ['Base Actual - Centro', 'Base Actual - La Mesa', 'Base Actual - Otay', 'Base Actual - El Florido'],
        'lat': [32.533, 32.515, 32.528, 32.463], 'lon': [-117.03, -116.98, -116.94, -116.82], 'tipo': ['Actual'] * 4
    })
    num_optimizadas = 12
    bases_optimizadas = pd.DataFrame({
        'nombre': [f'Estaci贸n Optimizada {i+1}' for i in range(num_optimizadas)],
        'lat': np.random.uniform(lat_min, lat_max, num_optimizadas),
        'lon': np.random.uniform(lon_min, lon_max, num_optimizadas), 'tipo': ['Optimizada'] * num_optimizadas
    })
    return df_llamadas, bases_actuales, bases_optimizadas

df_llamadas, bases_actuales, bases_optimizadas = cargar_datos()

# --- Sidebar Navigation ---
st.sidebar.title(" Navegaci贸n")
st.sidebar.markdown("""
Este dashboard presenta los hallazgos clave de la tesis de doctorado:
**"Sistema de despacho para ambulancias de la ciudad de Tijuana"**
---
*Autora:*
**M.C. Noelia Araceli Torres Cort茅s**
*Instituci贸n:*
**Tecnol贸gico Nacional de M茅xico / Instituto Tecnol贸gico de Tijuana**
*Directores de Tesis:*
- Dra. Yazmin Maldonado Robles
- Dr. Leonardo Trujillo Reyes
""")
pagina = st.sidebar.radio("Ir a:", 
    ["Resumen de la Tesis", "Datos y Correcci贸n de Tiempo", "Clustering de Demanda", "Optimizaci贸n de Ubicaciones", "Evoluci贸n del Sistema con IA Avanzada"]
)
st.sidebar.info("Los datos son simulados para fines de demostraci贸n, reflejando los conceptos y la geograf铆a de la investigaci贸n original.")

# --- Page Rendering ---

if pagina == "Resumen de la Tesis":
    st.title("Sistema de Despacho para Ambulancias de la Ciudad de Tijuana")
    # ... (El contenido de esta p谩gina es id茅ntico al de la versi贸n anterior) ...

elif pagina == "Datos y Correcci贸n de Tiempo":
    st.title("Exploraci贸n de Datos y Correcci贸n del Tiempo de Viaje")
    # ... (El contenido de esta p谩gina es id茅ntico al de la versi贸n anterior) ...

elif pagina == "Clustering de Demanda":
    st.title("Identificaci贸n de Puntos de Alta Demanda Mediante Clustering")
    # ... (El contenido de esta p谩gina es id茅ntico al de la versi贸n anterior) ...
    
elif pagina == "Optimizaci贸n de Ubicaciones":
    st.title("Optimizaci贸n de la Ubicaci贸n de Ambulancias")
    # ... (El contenido de esta p谩gina es id茅ntico al de la versi贸n anterior) ...

elif pagina == "Evoluci贸n del Sistema con IA Avanzada":
    st.title(" Evoluci贸n del Sistema con IA de Vanguardia")
    st.markdown("Esta secci贸n interactiva, dise帽ada por un SME en Machine Learning, demuestra c贸mo las bibliotecas de IA de c贸digo abierto pueden evolucionar el sistema actual hacia una plataforma de despacho predictiva y adaptativa en tiempo real.")

    tab1, tab2, tab3 = st.tabs(["**1. Modelos Predictivos Superiores**", "**2. Predicci贸n de Demanda**", "**3. Simulaci贸n y RL**"])

    with tab1:
        st.header("Mejora del Modelo de Correcci贸n de Tiempo")
        st.markdown("El modelo **Random Forest** de la tesis es robusto. Sin embargo, los modelos de **Gradient Boosting** como **XGBoost** y **LightGBM** son el est谩ndar actual en la industria para datos tabulares, ya que a menudo ofrecen mayor precisi贸n.")

        @st.cache_data
        def train_and_compare_models():
            X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, n_classes=3, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            # Random Forest (Baseline)
            rf = RandomForestClassifier(random_state=42)
            rf.fit(X_train, y_train)
            rf_preds = rf.predict(X_test)
            rf_acc = accuracy_score(y_test, rf_preds)
            
            # XGBoost
            import xgboost as xgb
            xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')
            xgb_model.fit(X_train, y_train)
            xgb_preds = xgb_model.predict(X_test)
            xgb_acc = accuracy_score(y_test, xgb_preds)
            
            # LightGBM
            import lightgbm as lgb
            lgb_model = lgb.LGBMClassifier(random_state=42)
            lgb_model.fit(X_train, y_train)
            lgb_preds = lgb_model.predict(X_test)
            lgb_acc = accuracy_score(y_test, lgb_preds)
            
            return {"Random Forest": rf_acc, "XGBoost": xgb_acc, "LightGBM": lgb_acc}

        if st.button("讹 Entrenar y Comparar Modelos Predictivos"):
            with st.spinner("Entrenando modelos en datos sint茅ticos..."):
                results = train_and_compare_models()
                st.success("隆Modelos entrenados!")
                
                df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy']).reset_index()
                df_results.rename(columns={'index': 'Modelo'}, inplace=True)
                
                fig = px.bar(df_results, x='Modelo', y='Accuracy', title='Comparaci贸n de Precisi贸n de Modelos',
                             text_auto='.2%', color='Modelo', color_discrete_map={
                                 "Random Forest": "#FFA07A", "XGBoost": "#20B2AA", "LightGBM": "#778899"
                             })
                fig.update_layout(yaxis=dict(range=[0.8, 1.0]))
                st.plotly_chart(fig, use_container_width=True)

                st.subheader("C贸digo de Implementaci贸n")
                st.code("""
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Asumiendo que X_train, y_train, X_test, y_test existen...

# XGBoost
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train)
xgb_acc = accuracy_score(y_test, xgb_model.predict(X_test))

# LightGBM
lgb_model = lgb.LGBMClassifier()
lgb_model.fit(X_train, y_train)
lgb_acc = accuracy_score(y_test, lgb_model.predict(X_test))
                """, language="python")

    with tab2:
        st.header("Pron贸stico Espacio-Temporal de la Demanda")
        st.markdown("En lugar de basar la ubicaci贸n en la demanda hist贸rica (d贸nde *ocurrieron* las llamadas), podemos usar modelos de series de tiempo como **Prophet** de Meta para predecir d贸nde y cu谩ndo *ocurrir谩n* las llamadas, permitiendo una reubicaci贸n proactiva.")

        days_to_forecast = st.slider("D铆as a pronosticar en el futuro:", 7, 90, 30)

        @st.cache_data
        def generate_forecast(days):
            from prophet import Prophet
            # Crear datos sint茅ticos de llamadas diarias
            start_date = "2022-01-01"
            periods = 365
            df = pd.DataFrame({'ds': pd.date_range(start_date, periods=periods)})
            # Simular estacionalidad (m谩s llamadas los fines de semana)
            df['day_of_week'] = df['ds'].dt.dayofweek
            noise = np.random.randn(periods) * 5
            df['y'] = 100 + df['day_of_week'] * 5 + np.sin(df.index/30) * 10 + noise
            df['y'] = df['y'].astype(int)
            
            model = Prophet()
            model.fit(df)
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            return model, forecast

        if st.button(" Generar Pron贸stico de Demanda"):
            with st.spinner(f"Calculando pron贸stico para los pr贸ximos {days_to_forecast} d铆as..."):
                model, forecast = generate_forecast(days_to_forecast)
                st.success("隆Pron贸stico generado!")
                
                fig = model.plot(forecast)
                st.pyplot(fig)

                st.subheader("C贸digo de Implementaci贸n con Prophet")
                st.code("""
from prophet import Prophet
import pandas as pd

# df debe tener columnas 'ds' (fecha) y 'y' (valor)
# df = pd.read_csv('historical_calls.csv') 

model = Prophet()
model.fit(df)

future_dataframe = model.make_future_dataframe(periods=30)
forecast = model.predict(future_dataframe)

fig = model.plot(forecast)
# st.pyplot(fig)
                """, language="python")

    with tab3:
        st.header("Simulaci贸n de Sistema con SimPy y Aprendizaje por Refuerzo")
        st.markdown("La optimizaci贸n definitiva es un sistema que aprende la mejor pol铆tica de despacho por s铆 mismo. Esto se logra con **Aprendizaje por Refuerzo (RL)**, entrenando a un 'agente' en un entorno simulado de alta fidelidad, que podemos construir con **SimPy**.")
        
        st.subheader("Demostraci贸n de Simulaci贸n con SimPy")
        
        num_ambulances = st.slider("N煤mero de ambulancias en el sistema:", 1, 10, 3)
        avg_call_interval = st.slider("Tiempo promedio entre llamadas (minutos):", 5, 60, 15)

        @st.cache_data
        def run_simulation(ambulances, interval):
            import simpy
            import random
            
            wait_times = []

            def call(env, call_id, ambulance_fleet):
                call_arrival_time = env.now
                with ambulance_fleet.request() as request:
                    yield request
                    wait_time = env.now - call_arrival_time
                    wait_times.append(wait_time)
                    
                    on_scene_time = random.uniform(15, 30)
                    yield env.timeout(on_scene_time)

            def call_generator(env, ambulance_fleet):
                call_id = 0
                while True:
                    yield env.timeout(random.expovariate(1.0 / interval))
                    call_id += 1
                    env.process(call(env, call_id, ambulance_fleet))

            env = simpy.Environment()
            ambulance_fleet = simpy.Resource(env, capacity=ambulances)
            env.process(call_generator(env, ambulance_fleet))
            env.run(until=1440) # Simular 24 horas (1440 minutos)
            
            return np.mean(wait_times) if wait_times else 0

        if st.button(" Ejecutar Simulaci贸n de 24 Horas"):
            with st.spinner("Simulando miles de eventos de despacho..."):
                avg_wait = run_simulation(num_ambulances, avg_call_interval)
                st.success("隆Simulaci贸n completada!")
                st.metric("Tiempo Promedio de Espera por una Ambulancia", f"{avg_wait:.2f} minutos")
                st.markdown("Un agente de RL ser铆a entrenado en este entorno para tomar decisiones que minimicen esta m茅trica.")

                st.subheader("C贸digo de Implementaci贸n con SimPy")
                st.code("""
import simpy
import random
import numpy as np

def run_simulation(num_ambulances, call_interval):
    env = simpy.Environment()
    ambulance_fleet = simpy.Resource(env, capacity=num_ambulances)
    wait_times = []

    def call(env, ambulance_fleet):
        with ambulance_fleet.request() as request:
            yield request # Espera por una ambulancia
            # ...l贸gica de servicio...
    
    def call_generator(env, ambulance_fleet):
        while True:
            yield env.timeout(random.expovariate(1.0 / call_interval))
            env.process(call(env, ambulance_fleet))

    env.process(call_generator(env, ambulance_fleet))
    env.run(until=1440) # Simular 24 horas
    return np.mean(wait_times)
                """, language="python")
