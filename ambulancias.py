# ==============================================================================
# LIBRARIES
# Import lightweight libraries at the top for fast startup.
# Heavy libraries are imported "just-in-time" inside their respective functions.
# ==============================================================================
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ==============================================================================
# PAGE CONFIGURATION
# ==============================================================================
st.set_page_config(
    page_title="Dashboard de Optimizaci贸n de Despacho de Ambulancias",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ==============================================================================
# DATA LOADING AND CACHING
# ==============================================================================
@st.cache_data
def cargar_datos():
    """
    Genera datos simulados realistas restringidos al 谩rea de Tijuana, M茅xico.
    This function is cached, so it only runs once.
    """
    lat_min, lat_max = 32.40, 32.55
    lon_min, lon_max = -117.12, -116.60
    num_llamadas = 500
    np.random.seed(42)
    latitudes = np.random.uniform(lat_min, lat_max, num_llamadas)
    longitudes = np.random.uniform(lon_min, lon_max, num_llamadas)
    tiempo_api = np.random.uniform(5, 30, num_llamadas)
    tiempo_real = tiempo_api * np.random.uniform(0.6, 0.95, num_llamadas)
    tiempo_corregido = tiempo_real * np.random.uniform(0.95, 1.05, num_llamadas)
    df_llamadas = pd.DataFrame({
        'lat': latitudes, 'lon': longitudes, 'tiempo_api_minutos': tiempo_api,
        'tiempo_real_minutos': tiempo_real, 'tiempo_corregido_minutos': tiempo_corregido
    })
    bases_actuales = pd.DataFrame({
        'nombre': ['Base Actual - Centro', 'Base Actual - La Mesa', 'Base Actual - Otay', 'Base Actual - El Florido'],
        'lat': [32.533, 32.515, 32.528, 32.463], 'lon': [-117.03, -116.98, -116.94, -116.82], 'tipo': ['Actual'] * 4
    })
    num_optimizadas = 12
    bases_optimizadas = pd.DataFrame({
        'nombre': [f'Estaci贸n Optimizada {i+1}' for i in range(num_optimizadas)],
        'lat': np.random.uniform(lat_min, lat_max, num_optimizadas),
        'lon': np.random.uniform(lon_min, lon_max, num_optimizadas), 'tipo': ['Optimizada'] * num_optimizadas
    })
    return df_llamadas, bases_actuales, bases_optimizadas

df_llamadas, bases_actuales, bases_optimizadas = cargar_datos()

# ==============================================================================
# SIDEBAR NAVIGATION
# ==============================================================================
st.sidebar.title(" Navegaci贸n")
st.sidebar.markdown("""
Este dashboard presenta los hallazgos clave de la tesis de doctorado:
**"Sistema de despacho para ambulancias de la ciudad de Tijuana"**
---
*Autora:*
**M.C. Noelia Araceli Torres Cort茅s**
*Instituci贸n:*
**Tecnol贸gico Nacional de M茅xico / Instituto Tecnol贸gico de Tijuana**
*Directores de Tesis:*
- Dra. Yazmin Maldonado Robles
- Dr. Leonardo Trujillo Reyes
""")

PAGES = [
    "Resumen de la Tesis",
    "Datos y Correcci贸n de Tiempo",
    "Clustering de Demanda",
    "Optimizaci贸n de Ubicaciones",
    "Evoluci贸n del Sistema con IA Avanzada"
]

pagina = st.sidebar.radio("Ir a:", PAGES)
st.sidebar.info("Los datos son simulados para fines de demostraci贸n, reflejando los conceptos y la geograf铆a de la investigaci贸n original.")

# ==============================================================================
# PAGE 1: RESUMEN DE LA TESIS
# ==============================================================================
if pagina == "Resumen de la Tesis":
    st.title("Sistema de Despacho para Ambulancias de la Ciudad de Tijuana")
    st.subheader("Dashboard de la Tesis de Doctorado por la M.C. Noelia Araceli Torres Cort茅s")
    
    st.markdown("""
    Este dashboard proporciona un resumen interactivo de la investigaci贸n doctoral destinada a optimizar los Servicios M茅dicos de Emergencia (SME) para la Cruz Roja en Tijuana, M茅xico (CRT). El proyecto aborda el desaf铆o cr铆tico de reducir los tiempos de respuesta de las ambulancias en una ciudad con recursos limitados y condiciones urbanas complejas.
    """)
    
    with st.expander("**Fundamento Matem谩tico del Problema General**"):
        st.markdown(r"""
        Desde una perspectiva matem谩tica, el problema central abordado en esta tesis es un **problema de optimizaci贸n combinatoria** conocido como un **Problema de Localizaci贸n-Asignaci贸n** (*Location-Allocation Problem*), espec铆ficamente formulado como un **Problema de Cobertura** (*Covering Problem*).

        El objetivo general es determinar la ubicaci贸n 贸ptima de un conjunto de $P$ ambulancias (recursos) en un conjunto de $J$ posibles localizaciones para maximizar la cobertura de un conjunto de $I$ puntos de demanda, sujeto a restricciones de tiempo de respuesta y recursos.

        La formulaci贸n matem谩tica busca optimizar una funci贸n objetivo, $f(Y)$, donde $Y$ es el conjunto de decisiones de localizaci贸n, para maximizar una m茅trica de efectividad del sistema (ej. el n煤mero de llamadas cubiertas). La novedad de esta tesis radica en la **calibraci贸n de los par谩metros del modelo** (espec铆ficamente los tiempos de viaje $t_{ij}$) mediante t茅cnicas de aprendizaje autom谩tico, uniendo as铆 dos dominios matem谩ticos: la **investigaci贸n de operaciones** y la **estad铆stica computacional**.
        """)
        
    st.header("Contribuci贸n Principal y Novedad")
    col1, col2 = st.columns(2)
    with col1:
        st.info(" **Modelo de Correcci贸n de Tiempo de Viaje**")
        st.write("""
        La innovaci贸n principal es un modelo de aprendizaje autom谩tico que corrige las estimaciones de tiempo de viaje de las API est谩ndar (como OSRM). Aprende la discrepancia entre las predicciones de la API y los tiempos de viaje reales de las ambulancias, teniendo en cuenta factores como el uso de la sirena y las exenciones a las leyes de tr谩nsito. Esto result贸 en una **mejora del 20% en la cobertura de ubicaci贸n**.
        """)
    with col2:
        st.info(" **Aplicaci贸n en el Mundo Real**")
        st.write("""
        A diferencia de los estudios en ciudades bien estructuradas, esta investigaci贸n aborda la realidad 'desordenada' de una regi贸n en desarrollo. Al crear una soluci贸n pr谩ctica y basada en datos para la Cruz Roja de Tijuana, cierra la brecha entre la teor铆a acad茅mica y el impacto en el terreno. El modelo final utiliza **OSRM**, una herramienta gratuita y de c贸digo abierto, haci茅ndolo una **soluci贸n sostenible para la organizaci贸n**, que no puede subsidiar gastos en APIs comerciales.
        """)

# ==============================================================================
# PAGE 2: DATOS Y CORRECCIN DE TIEMPO
# ==============================================================================
elif pagina == "Datos y Correcci贸n de Tiempo":
    st.title("Exploraci贸n de Datos y Correcci贸n del Tiempo de Viaje")
    st.markdown("Un desaf铆o fundamental en la optimizaci贸n del despacho de ambulancias es predecir con precisi贸n cu谩nto tiempo tardar谩 una ambulancia en llegar a un incidente.")
    st.subheader("Mapa de Llamadas de Emergencia Simuladas en Tijuana")
    st.map(df_llamadas[['lat', 'lon']], zoom=11, use_container_width=True)
    st.subheader("Correcci贸n de las Estimaciones de Tiempo de Viaje")

    with st.expander("**Fundamento Matem谩tico del Modelo de Correcci贸n**"):
        st.markdown(r"""
        La decisi贸n clave de la tesis es transformar el problema de **regresi贸n** (predecir un valor continuo) en **clasificaci贸n**. Esto aumenta la robustez del modelo frente a valores at铆picos.
        """)
        st.latex(r''' \epsilon = T_{\text{API}} - T_{\text{real}} \quad \rightarrow \quad \hat{c} = f(X) \quad \rightarrow \quad T_{\text{corregido}} = T_{\text{API}} - \Delta_{\hat{c}} ''')
        st.markdown(r"Este enfoque predice una 'categor铆a de viaje' con mayor certeza y aplica una correcci贸n robusta (mediana) para esa categor铆a.")

    error_antes = df_llamadas['tiempo_api_minutos'] - df_llamadas['tiempo_real_minutos']
    error_despues = df_llamadas['tiempo_corregido_minutos'] - df_llamadas['tiempo_real_minutos']
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Antes de la Correcci贸n** (API vs. Tiempo Real)")
        fig1 = px.histogram(error_antes, nbins=50, title="Distribuci贸n del Error (API - Real)")
        fig1.update_layout(yaxis_title="Frecuencia", xaxis_title="Error de Tiempo (minutos)")
        st.plotly_chart(fig1, use_container_width=True)
    with col2:
        st.markdown("**Despu茅s de la Correcci贸n** (Modelo ML vs. Tiempo Real)")
        fig2 = px.histogram(error_despues, nbins=50, title="Distribuci贸n del Error (Corregido - Real)")
        fig2.update_layout(yaxis_title="Frecuencia", xaxis_title="Error de Tiempo (minutos)")
        st.plotly_chart(fig2, use_container_width=True)

# ==============================================================================
# PAGE 3: CLUSTERING DE DEMANDA
# ==============================================================================
elif pagina == "Clustering de Demanda":
    st.title("Identificaci贸n de Puntos de Alta Demanda Mediante Clustering")
    st.markdown("Para determinar d贸nde ubicar las ambulancias, las llamadas de emergencia hist贸ricas se agruparon utilizando K-Means. El centro de cada cl煤ster representa un 'punto de demanda'.")
    with st.expander("**Fundamento Matem谩tico del Clustering K-Means**"):
        st.markdown(r"K-Means particiona $n$ observaciones en $k$ cl煤steres al minimizar la suma de cuadrados dentro del cl煤ster (WCSS):")
        st.latex(r''' \arg\min_{S} \sum_{i=1}^{k} \sum_{x \in S_i} \|x - \mu_i\|^2 ''')
        st.markdown(r"Los centroides resultantes, $\mu_i$, son los **centros de masa de la demanda**, reduciendo la complejidad del problema para la etapa de optimizaci贸n.")

    k = st.slider("Seleccione el N煤mero de Cl煤steres de Demanda (k):", min_value=5, max_value=25, value=15, step=1)
    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
    df_llamadas['cluster'] = kmeans.fit_predict(df_llamadas[['lat', 'lon']])
    centroides = kmeans.cluster_centers_
    df_centroides = pd.DataFrame(centroides, columns=['lat', 'lon'])
    
    st.subheader(f"Mapa de {k} Cl煤steres de Llamadas de Emergencia")
    fig = px.scatter_map(
        df_llamadas, lat="lat", lon="lon", color="cluster", zoom=10, height=600,
        title="Llamadas de Emergencia Coloreadas por Cl煤ster"
    )
    fig.add_scattermapbox(
        lat=df_centroides['lat'], lon=df_centroides['lon'], mode='markers',
        marker=dict(size=15, symbol='star', color='red'), name='Punto de Alta Demanda'
    )
    st.plotly_chart(fig, use_container_width=True)

# ==============================================================================
# PAGE 4: OPTIMIZACIN DE UBICACIONES
# ==============================================================================
elif pagina == "Optimizaci贸n de Ubicaciones":
    st.title("Optimizaci贸n de la Ubicaci贸n de Ambulancias")
    st.markdown("Utilizando los puntos de alta demanda y los tiempos de viaje corregidos, se utiliz贸 el Modelo Robusto de Doble Est谩ndar (RDSM) para encontrar las ubicaciones 贸ptimas.")
    
    with st.expander("**Fundamento Matem谩tico del Modelo de Optimizaci贸n (RDSM)**"):
        st.markdown(r"El RDSM es un modelo de **programaci贸n lineal entera binaria** que busca maximizar la cobertura doble ponderada.")
        st.latex(r''' \text{Maximizar} \quad Z = \sum_{i \in I} w_i z_i \quad \text{sujeto a} \quad \sum_{j \in J, t_{ij} \le T_{\text{crit}}} y_j \ge 2z_i, \quad \sum y_j \le P ''')
        st.markdown(r"La soluci贸n $\{y_j^*\}$ representa la configuraci贸n de bases **probablemente 贸ptima**, anclada a la realidad operacional mediante los tiempos de viaje corregidos por ML.")

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Resultados de la Optimizaci贸n")
        st.metric(label="Cobertura Doble (Antes de Correcci贸n)", value="80.0%", help="Cobertura usando tiempos de API est谩ndar.")
        st.metric(label="Cobertura Doble (Despu茅s de Correcci贸n)", value="100%", delta="20.0%", help="Cobertura usando tiempos corregidos por ML, demostrando el impacto del proyecto.")
    with col2:
        st.subheader("Ubicaciones de Ambulancias: Optimizadas vs. Actuales")
        todas_las_bases = pd.concat([bases_actuales, bases_optimizadas], ignore_index=True)
        fig = px.scatter_map(
            todas_las_bases, lat="lat", lon="lon", color="tipo",
            title="Comparaci贸n de Ubicaciones de Bases",
            hover_name="nombre",
            color_discrete_map={"Actual": "orange", "Optimizada": "green"}
        )
        st.plotly_chart(fig, use_container_width=True)

# ==============================================================================
# PAGE 5: EVOLUCIN DEL SISTEMA CON IA AVANZADA (INTERACTIVE DEMOS)
# ==============================================================================
elif pagina == "Evoluci贸n del Sistema con IA Avanzada":
    st.title(" Evoluci贸n del Sistema con IA de Vanguardia")
    st.markdown("Esta secci贸n interactiva demuestra c贸mo las bibliotecas de IA de c贸digo abierto pueden evolucionar el sistema actual hacia una plataforma de despacho predictiva y adaptativa en tiempo real.")

    tab1, tab2, tab3 = st.tabs(["**1. Modelos Predictivos Superiores**", "**2. Predicci贸n de Demanda**", "**3. Simulaci贸n y RL**"])

    with tab1:
        st.header("Mejora del Modelo de Correcci贸n de Tiempo")
        st.markdown("El modelo **Random Forest** de la tesis es robusto. Sin embargo, los modelos de **Gradient Boosting** como **XGBoost** y **LightGBM** son el est谩ndar actual en la industria para datos tabulares, ya que a menudo ofrecen mayor precisi贸n.")

        @st.cache_data
        def train_and_compare_models():
            """Trains and compares RandomForest, XGBoost, and LightGBM models."""
            import xgboost as xgb
            import lightgbm as lgb
            X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, n_classes=3, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            rf = RandomForestClassifier(random_state=42).fit(X_train, y_train)
            rf_acc = accuracy_score(y_test, rf.predict(X_test))
            xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss').fit(X_train, y_train)
            xgb_acc = accuracy_score(y_test, xgb_model.predict(X_test))
            lgb_model = lgb.LGBMClassifier(random_state=42).fit(X_train, y_train)
            lgb_acc = accuracy_score(y_test, lgb_model.predict(X_test))
            return {"Random Forest": rf_acc, "XGBoost": xgb_acc, "LightGBM": lgb_acc}

        if st.button("讹 Entrenar y Comparar Modelos Predictivos"):
            with st.spinner("Entrenando modelos... (Puede tardar la primera vez)"):
                results = train_and_compare_models()
                st.success("隆Modelos entrenados!")
                df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy']).reset_index()
                fig = px.bar(df_results, x='index', y='Accuracy', title='Comparaci贸n de Precisi贸n', text_auto='.2%')
                st.plotly_chart(fig, use_container_width=True)

    with tab2:
        st.header("Pron贸stico Espacio-Temporal de la Demanda")
        st.markdown("En lugar de basar la ubicaci贸n en la demanda hist贸rica, podemos usar modelos como **Prophet** para predecir d贸nde y cu谩ndo *ocurrir谩n* las llamadas.")
        days_to_forecast = st.slider("D铆as a pronosticar en el futuro:", 7, 90, 30)

        @st.cache_data
        def generate_forecast(days):
            """Generates a time series forecast using Prophet."""
            from prophet import Prophet
            start_date = "2022-01-01"
            periods = 365
            df = pd.DataFrame({'ds': pd.date_range(start_date, periods=periods)})
            df['y'] = 100 + (df['ds'].dt.dayofweek // 5) * 25 + np.sin(df.index / 365 * 2 * np.pi) * 10 + np.random.randn(periods) * 5
            model = Prophet(weekly_seasonality=True, yearly_seasonality=True).fit(df)
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            return model, forecast

        if st.button(" Generar Pron贸stico de Demanda"):
            with st.spinner(f"Calculando pron贸stico... (La primera ejecuci贸n de Prophet puede ser lenta)"):
                model, forecast = generate_forecast(days_to_forecast)
                st.success("隆Pron贸stico generado!")
                fig = model.plot(forecast)
                st.pyplot(fig)

    with tab3:
        st.header("Simulaci贸n de Sistema con SimPy")
        st.markdown("Para entrenar un agente de **Aprendizaje por Refuerzo (RL)**, primero necesitamos un entorno simulado. **SimPy** nos permite crear un 'gemelo digital' de la operaci贸n de despacho.")
        num_ambulances = st.slider("N煤mero de ambulancias en el sistema:", 1, 10, 3)
        avg_call_interval = st.slider("Tiempo promedio entre llamadas (minutos):", 5, 60, 15)

        @st.cache_data
        def run_simulation(ambulances, interval, num_calls_to_sim):
            """Runs a discrete-event simulation of an ambulance dispatch system."""
            import simpy
            import random
            wait_times = []
            def call_process(env, ambulance_fleet):
                call_arrival_time = env.now
                with ambulance_fleet.request() as request:
                    yield request
                    wait_times.append(env.now - call_arrival_time)
                    yield env.timeout(random.uniform(20, 45))
            def call_generator(env, ambulance_fleet, interval):
                for i in range(num_calls_to_sim):
                    env.process(call_process(env, ambulance_fleet))
                    yield env.timeout(random.expovariate(1.0 / interval))
            env = simpy.Environment()
            ambulance_fleet = simpy.Resource(env, capacity=ambulances)
            env.process(call_generator(env, ambulance_fleet, interval))
            env.run()
            return np.mean(wait_times) if wait_times else 0

        if st.button(" Ejecutar Simulaci贸n de Despacho"):
            with st.spinner("Simulando cientos de llamadas y despachos..."):
                avg_wait = run_simulation(num_ambulances, avg_call_interval, num_calls_to_sim=500)
                st.success("隆Simulaci贸n completada!")
                st.metric("Tiempo Promedio de Espera por una Ambulancia", f"{avg_wait:.2f} minutos")
                st.markdown("Un agente de **Aprendizaje por Refuerzo** ser铆a entrenado para tomar decisiones que minimicen esta m茅trica.")
