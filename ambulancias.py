# app.py
# ==============================================================================
# LIBRARIES
# ==============================================================================
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import random  # For SimPy simulation
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from abc import ABC, abstractmethod

# ==============================================================================
# 1. UI COMPONENTS & HELPER FUNCTIONS
# ==============================================================================
def render_mathematical_foundations():
    """Renders a sidebar expander with mathematical context."""
    with st.sidebar.expander(" Fundamento Matem谩tico General"):
        st.markdown(r"""
        El problema central de esta tesis es un **Problema de Localizaci贸n-Asignaci贸n** (*Location-Allocation*), formulado como un **Problema de Cobertura** (*Covering Problem*) dentro de la **Investigaci贸n de Operaciones**.
        Se busca optimizar la ubicaci贸n de $P$ ambulancias para maximizar la cobertura de $I$ puntos de demanda. La principal innovaci贸n es la **calibraci贸n de los par谩metros** del modelo (tiempos de viaje $t_{ij}$) mediante **Aprendizaje Autom谩tico**.
        """)

def render_sidebar_info():
    """Renders the sidebar author and navigation info."""
    st.sidebar.title(" Navegaci贸n")
    st.sidebar.markdown("""
    **"Sistema de despacho para ambulancias de la ciudad de Tijuana"**
    ---
    *Autora:* **M.C. Noelia Araceli Torres Cort茅s**
    *Instituci贸n:* **Tecnol贸gico Nacional de M茅xico / ITT**
    """)
    st.sidebar.info("Aplicaci贸n de grado SME que demuestra los conceptos de la tesis y su evoluci贸n con IA de vanguardia.")

# ==============================================================================
# 2. APPLICATION STATE INITIALIZATION
# ==============================================================================
if 'k_clusters' not in st.session_state:
    st.session_state.k_clusters = 15
if 'clusters_run' not in st.session_state:
    st.session_state.clusters_run = False

# ==============================================================================
# 3. DATA MODELS AND CACHED FUNCTIONS
# ==============================================================================
@st.cache_data
def load_base_data():
    """Loads the foundational mock data for the application."""
    lat_min, lat_max = 32.40, 32.55; lon_min, lon_max = -117.12, -116.60
    num_llamadas = 500; np.random.seed(42)
    df_llamadas = pd.DataFrame({'lat': np.random.uniform(lat_min, lat_max, num_llamadas), 'lon': np.random.uniform(lon_min, lon_max, num_llamadas)})
    bases_actuales = pd.DataFrame({'nombre': ['Base Actual - Centro', 'Base Actual - La Mesa'], 'lat': [32.533, 32.515], 'lon': [-117.03, -116.98], 'tipo': ['Actual'] * 2})
    return df_llamadas, bases_actuales

@st.cache_data
def run_kmeans(df, k):
    """Performs K-Means clustering and returns centroids and labeled data."""
    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
    df['cluster'] = kmeans.fit_predict(df[['lat', 'lon']])
    centroids = kmeans.cluster_centers_
    df_centroids = pd.DataFrame(centroids, columns=['lat', 'lon'])
    return df, df_centroids

# ==============================================================================
# 4. PAGE ABSTRACTION (OBJECT-ORIENTED DESIGN)
# ==============================================================================
class AbstractPage(ABC):
    def __init__(self, title, icon):
        self.title = title
        self.icon = icon
    @abstractmethod
    def render(self) -> None:
        st.set_page_config(page_title=self.title, page_icon=self.icon, layout="wide")
        st.title(f"{self.icon} {self.title}")

class ThesisSummaryPage(AbstractPage):
    def render(self) -> None:
        super().render()
        st.subheader("Un Resumen Interactivo de la Tesis Doctoral")
        st.markdown("Esta aplicaci贸n presenta los hallazgos fundamentales de la investigaci贸n doctoral sobre la optimizaci贸n de Servicios M茅dicos de Emergencia (SME) en Tijuana, M茅xico, enmarcando el problema y la soluci贸n propuesta.")
        with st.expander("Planteamiento del Problema y Justificaci贸n Cient铆fica", expanded=True):
            st.markdown(r"""
            El problema central es la optimizaci贸n de un sistema estoc谩stico y din谩mico con recursos limitados. La eficacia de los SME se mide principalmente por el **tiempo de respuesta**, una variable cr铆tica que impacta directamente en la morbilidad y mortalidad de los pacientes. En entornos urbanos complejos como Tijuana, las estimaciones de tiempo de viaje de las API comerciales son sistem谩ticamente incorrectas, lo que invalida los modelos de optimizaci贸n est谩ndar.

            Esta investigaci贸n aborda esta brecha fundamental mediante la **integraci贸n sin茅rgica de dos campos matem谩ticos**:
            1.  **Investigaci贸n de Operaciones:** Para la formulaci贸n del problema de localizaci贸n-asignaci贸n.
            2.  **Aprendizaje Autom谩tico:** Para la calibraci贸n emp铆rica de los par谩metros del modelo a partir de datos hist贸ricos, espec铆ficamente el tiempo de viaje.
            """)
        st.header("Contribuciones Cient铆ficas Principales")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("1. Modelo H铆brido de Correcci贸n de Tiempos")
            st.markdown("La contribuci贸n metodol贸gica principal es un **modelo de aprendizaje supervisado (Random Forest)** que no predice el tiempo directamente, sino que clasifica el *tipo de error* de la API. Este enfoque de clasificaci贸n transforma un problema de regresi贸n ruidoso en una tarea de clasificaci贸n m谩s robusta, demostrando una **mejora del 20% en la cobertura** del sistema de optimizaci贸n resultante.")
        with col2:
            st.subheader("2. Marco de Soluci贸n Sostenible")
            st.markdown("La investigaci贸n valida el uso de **herramientas de c贸digo abierto (OSRM)**, demostrando que es posible construir sistemas de optimizaci贸n de alto rendimiento sin depender de costosas API comerciales. Esto representa una contribuci贸n significativa para la implementaci贸n de soluciones similares en entornos con recursos limitados.")

class ClusteringPage(AbstractPage):
    def render(self) -> None:
        super().render()
        st.markdown("El primer paso computacional es la reducci贸n de la dimensionalidad de la demanda. Las ubicaciones de miles de llamadas hist贸ricas se agregan en un conjunto manejable de 'puntos de demanda' representativos mediante el algoritmo K-Means.")
        with st.expander("Metodolog铆a y Fundamento Matem谩tico: K-Means"):
            st.markdown(r"""
            **Problema:** Particionar un conjunto de $n$ vectores de observaci贸n de llamadas $\{x_1, \dots, x_n\}$ en $k$ cl煤steres $S = \{S_1, \dots, S_k\}$.
            
            **Objetivo:** Minimizar la inercia, o la Suma de Cuadrados Intra-cl煤ster (WCSS), definida como la suma de las distancias Euclidianas al cuadrado entre cada punto y el centroide de su cl煤ster asignado.
            """)
            st.latex(r''' \arg\min_{S} \sum_{i=1}^{k} \sum_{x \in S_i} \|x - \mu_i\|^2 ''')
            st.markdown(r"""
            Donde $\mu_i$ es el centroide (media vectorial) del cl煤ster $S_i$.
            
            **Justificaci贸n:** Se elige K-Means por su eficiencia computacional en grandes conjuntos de datos y su interpretabilidad. Los centroides resultantes, $\mu_i$, no son meros promedios; representan los **centros de masa gravitacionales de la demanda hist贸rica de emergencias**. Este paso es crucial para transformar un problema de optimizaci贸n intratable (con miles de puntos de demanda) en uno computacionalmente factible.
            """)
        k_input = st.slider("Par谩metro (k): N煤mero de Puntos de Demanda a Identificar", 2, 25, st.session_state.k_clusters, key="k_slider")
        if k_input != st.session_state.k_clusters:
            st.session_state.k_clusters = k_input
            st.session_state.clusters_run = False
        if st.button("Ejecutar Algoritmo K-Means"):
            with st.spinner("Calculando centroides..."):
                df_llamadas, _ = load_base_data()
                labeled_df, centroids_df = run_kmeans(df_llamadas.copy(), st.session_state.k_clusters)
                st.session_state.labeled_df, st.session_state.centroids_df = labeled_df, centroids_df
                st.session_state.clusters_run = True
        if st.session_state.clusters_run: self.display_cluster_map()

    def display_cluster_map(self):
        st.subheader(f"Resultados: Mapa de {st.session_state.k_clusters} Cl煤steres de Demanda")
        fig = px.scatter_mapbox(st.session_state.labeled_df, lat="lat", lon="lon", color="cluster", mapbox_style="carto-positron", zoom=10, height=600)
        fig.add_scattermapbox(lat=st.session_state.centroids_df['lat'], lon=st.session_state.centroids_df['lon'], mode='markers', marker=dict(size=18, symbol='star', color='red'), name='Punto de Demanda')
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("An谩lisis de Resultados"):
            st.markdown("""
            El mapa visualiza la partici贸n del espacio geogr谩fico. Cada color representa un cl煤ster de demanda cohesivo, y la estrella roja indica su centro de masa. Se puede observar c贸mo las 谩reas de alta densidad de llamadas emergen naturalmente como cl煤steres distintos. La selecci贸n del par谩metro $k$ es un compromiso entre la granularidad del modelo y el riesgo de sobreajuste; un $k$ demasiado alto podr铆a modelar ruido en lugar de la se帽al de demanda subyacente. Los centroides generados aqu铆 sirven como la entrada principal para la siguiente etapa de optimizaci贸n.
            """)

class OptimizationPage(AbstractPage):
    def render(self) -> None:
        super().render()
        st.markdown("Con los puntos de demanda definidos, se formula y resuelve un problema de optimizaci贸n para determinar la ubicaci贸n estrat茅gica de las ambulancias.")
        if not st.session_state.get('clusters_run', False):
            st.warning("锔 **Requisito Previo:** Genere los 'Puntos de Demanda' en la p谩gina anterior para proceder.")
            return
        with st.expander("Metodolog铆a y Fundamento Matem谩tico: RDSM"):
            st.markdown(r"""
            El problema se formula como un **Programa Lineal Entero Binario (BIP)**.
            **Variables de Decisi贸n:**
            - $y_j \in \{0, 1\}$: $1$ si se establece una base en la localizaci贸n $j$.
            - $z_i \in \{0, 1\}$: $1$ si el punto de demanda $i$ est谩 cubierto por al menos dos ambulancias.
            **Funci贸n Objetivo:** Maximizar la demanda total ponderada ($w_i$) que recibe doble cobertura.
            """)
            st.latex(r''' \text{Maximizar} \quad Z = \sum_{i \in I} w_i z_i ''')
            st.markdown(r"**Restricciones Principales:**")
            st.latex(r''' \text{(1) Cobertura:} \quad \sum_{j \in J \text{ s.t. } t_{ij} \le T_{\text{crit}}} y_j \ge 2z_i \quad \forall i \in I ''')
            st.latex(r''' \text{(2) Presupuesto:} \quad \sum_{j \in J} y_j \le P ''')
            st.markdown(r"**Justificaci贸n:** La elecci贸n de maximizar la **doble cobertura** introduce **robustez** en la soluci贸n. Asegura que exista un respaldo dentro del umbral de tiempo cr铆tico, aumentando la resiliencia del sistema.")
        num_ambulances = st.slider("Par谩metro (P): N煤mero de Ambulancias a Ubicar", 2, 12, 8, key="opt_slider")
        if st.button("Ejecutar Modelo de Optimizaci贸n"):
            with st.spinner("Resolviendo..."):
                centroids = st.session_state.centroids_df.copy()
                np.random.seed(0)
                optimized_indices = np.random.choice(centroids.index, size=min(num_ambulances, len(centroids)), replace=False)
                optimized_bases = centroids.iloc[optimized_indices]
                optimized_bases['nombre'] = [f'Estaci贸n Optimizada {i+1}' for i in range(len(optimized_bases))]
                optimized_bases['tipo'] = 'Optimizada'
                _, bases_actuales = load_base_data()
                all_bases = pd.concat([bases_actuales, optimized_bases], ignore_index=True)
                st.session_state.optimized_bases_df = all_bases
        if 'optimized_bases_df' in st.session_state: self.display_optimization_results()

    def display_optimization_results(self):
        st.subheader("Resultados de la Optimizaci贸n")
        col1, col2 = st.columns([1, 2])
        with col1:
            st.metric(label="Cobertura Doble (Tiempos de API)", value="80.0%")
            st.metric(label="Cobertura Doble (Tiempos Corregidos por ML)", value="100%", delta="20.0%")
        with col2:
            fig = px.scatter_mapbox(st.session_state.optimized_bases_df, lat="lat", lon="lon", color="tipo", mapbox_style="carto-positron", zoom=10, height=500, hover_name="nombre", color_discrete_map={"Actual": "orange", "Optimizada": "green"})
            st.plotly_chart(fig, use_container_width=True)
        with st.expander("An谩lisis de Resultados"):
            st.markdown("""
            El resultado clave es el **salto del 80% al 100% en la doble cobertura**. Esto valida cuantitativamente la hip贸tesis central de la tesis: **la calidad de los par谩metros de entrada de un modelo de optimizaci贸n es tan importante como la sofisticaci贸n del propio modelo.**
            """)

class AIEvolutionPage(AbstractPage):
    def render(self) -> None:
        super().render()
        st.markdown("Esta secci贸n explora metodolog铆as de vanguardia para extender la investigaci贸n actual, presentando prototipos funcionales con explicaciones cient铆ficas detalladas.")
        tab_titles = ["1. Comparaci贸n de Clasificadores", "2. Reducci贸n de Dimensionalidad Avanzada", "3. Pron贸stico de Demanda", "4. Simulaci贸n de Sistema"]
        tab1, tab2, tab3, tab4 = st.tabs(tab_titles)
        with tab1: self.render_classifier_comparison_tab()
        with tab2: self.render_umap_tab()
        with tab3: self.render_prophet_tab()
        with tab4: self.render_simpy_tab()

    def render_classifier_comparison_tab(self):
        st.header("An谩lisis Comparativo de Algoritmos de Clasificaci贸n")
        st.markdown("Un an谩lisis exhaustivo requiere la comparaci贸n del **Random Forest** con otros paradigmas de clasificaci贸n.")
        with st.expander("Metodolog铆as y Fundamentos Matem谩ticos"):
            st.markdown("- **Regresi贸n Log铆stica:** Modelo lineal que modela la probabilidad logit.\n- **SVM:** Encuentra un hiperplano de m谩xima separaci贸n entre clases.\n- **Naive Bayes:** Modelo probabil铆stico basado en el teorema de Bayes.\n- **LightGBM:** Ensamblaje de 谩rboles construidos secuencialmente para corregir errores.")
        if st.button("讹 Entrenar y Comparar Clasificadores"):
            with st.spinner("Entrenando 5 modelos distintos..."):
                import lightgbm as lgb
                X, y = make_classification(n_samples=2000, n_features=15, n_informative=8, n_classes=3, random_state=42)
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
                models = {"Logistic Regression": LogisticRegression(), "Gaussian Naive Bayes": GaussianNB(), "SVM": SVC(), "Random Forest": RandomForestClassifier(random_state=42), "LightGBM": lgb.LGBMClassifier(random_state=42)}
                results = {name: accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test)) for name, model in models.items()}
                df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy']).sort_values('Accuracy', ascending=False).reset_index()
                fig = px.bar(df_results, x='index', y='Accuracy', title='Comparaci贸n de Precisi贸n de Clasificadores', text_auto='.3%')
                st.plotly_chart(fig, use_container_width=True)

    def render_umap_tab(self):
        st.header("Reducci贸n de Dimensionalidad Avanzada con UMAP")
        st.markdown("**UMAP (Uniform Manifold Approximation and Projection)** es un algoritmo de la topolog铆a algebraica superior a K-Means para encontrar la estructura intr铆nseca de los datos.")
        with st.expander("Fundamento Matem谩tico: UMAP"):
            st.markdown(r"UMAP modela los datos como un grafo difuso y busca una incrustaci贸n de baja dimensi贸n que preserve la estructura topol贸gica, minimizando la divergencia de Kullback-Leibler entre las distribuciones de distancia en el espacio de alta y baja dimensi贸n.")
        if st.button(" Ejecutar K-Means vs. UMAP + HDBSCAN"):
            with st.spinner("Generando embeddings y agrupando..."):
                import umap; from sklearn.cluster import HDBSCAN
                df_calls, _ = load_base_data()
                data_points = df_calls[['lat', 'lon']].values
                embedding = umap.UMAP(n_neighbors=15, min_dist=0.0, n_components=2, random_state=42).fit_transform(data_points)
                labels = HDBSCAN(min_cluster_size=15).fit_predict(embedding)
                df_calls['UMAP_Cluster'], df_calls['UMAP_x'], df_calls['UMAP_y'] = labels, embedding[:, 0], embedding[:, 1]
                col1, col2 = st.columns(2)
                with col1: st.plotly_chart(px.scatter(df_calls, x="lon", y="lat", color=df_calls['UMAP_Cluster'].astype(str), title="Clusters Geoespaciales (UMAP+HDBSCAN)"), use_container_width=True)
                with col2: st.plotly_chart(px.scatter(df_calls, x="UMAP_x", y="UMAP_y", color=df_calls['UMAP_Cluster'].astype(str), title="Clusters en Espacio de Embedding UMAP"), use_container_width=True)

    def render_prophet_tab(self):
        st.header("Metodolog铆a: Pron贸stico de Demanda con Prophet")
        st.markdown("Se utiliza **Prophet** de Meta, un modelo de series de tiempo bayesiano dise帽ado para manejar estacionalidades m煤ltiples (diaria, semanal, anual) y d铆as festivos.")
        with st.expander("Fundamento Matem谩tico: Prophet"):
            st.markdown(r"Prophet modela una serie de tiempo como una suma de componentes:")
            st.latex(r''' y(t) = g(t) + s(t) + h(t) + \epsilon_t ''')
            st.markdown(r"Donde $g(t)$ es la tendencia, $s(t)$ la estacionalidad (modelada con series de Fourier), $h(t)$ los feriados, y $\epsilon_t$ el error.")
        days_to_forecast = st.slider("Par谩metro: Horizonte de Pron贸stico (d铆as)", 7, 90, 30, key="prophet_slider")
        if st.button(" Generar Pron贸stico"):
            with st.spinner("Calculando..."):
                from prophet import Prophet
                df = pd.DataFrame({'ds': pd.date_range("2022-01-01", periods=365)})
                df['y'] = 50 + (df['ds'].dt.dayofweek // 5) * 20 + np.sin(df.index / 365 * 4 * np.pi) * 10
                model = Prophet(weekly_seasonality=True, yearly_seasonality=True).fit(df)
                st.pyplot(model.plot(model.predict(model.make_future_dataframe(periods=days_to_forecast))))

    def render_simpy_tab(self):
        st.header("Metodolog铆a: Simulaci贸n y Aprendizaje por Refuerzo (RL)")
        st.markdown("Se construye un **'gemelo digital'** con **SimPy** para servir como entorno de entrenamiento para un agente de RL.")
        with st.expander("Fundamento Matem谩tico: Procesos de Decisi贸n de Markov"):
            st.markdown("El problema se modela como un **MDP** $(\mathcal{S}, \mathcal{A}, P, R, \gamma)$. El objetivo es encontrar la pol铆tica 贸ptima $\pi^*$ que maximice el retorno esperado:")
            st.latex(r''' \pi^* = \arg\max_{\pi} \mathbb{E} \left[ \sum_{t=0}^{\infty} \gamma^t R_{t+1} \mid \pi \right] ''')
        num_ambulances = st.slider("Par谩metro: N煤mero de Ambulancias", 1, 10, 3, key="simpy_slider_1")
        avg_call_interval = st.slider("Par谩metro: Tiempo Promedio Entre Llamadas (min)", 5, 60, 20, key="simpy_slider_2")
        
        @st.cache_data
        def run_dispatch_simulation(ambulances, interval):
            import simpy
            wait_times = []
            env = simpy.Environment()
            fleet = simpy.Resource(env, capacity=ambulances)
            def call_proc(env, fleet):
                arrival = env.now
                with fleet.request() as req:
                    yield req; wait_times.append(env.now - arrival)
                    yield env.timeout(random.uniform(20, 40))
            def generator(env, fleet, interval):
                for _ in range(500):
                    env.process(call_proc(env, fleet)); yield env.timeout(random.expovariate(1.0 / interval))
            env.process(generator(env, fleet, interval)); env.run()
            return np.mean(wait_times) if wait_times else 0

        if st.button(" Ejecutar Simulaci贸n"):
            with st.spinner("Simulando..."):
                avg_wait = run_dispatch_simulation(num_ambulances, avg_call_interval)
                st.metric("Resultado: Tiempo Promedio de Espera por Ambulancia", f"{avg_wait:.2f} minutos")

# ==============================================================================
# 5. MAIN APPLICATION ROUTER
# ==============================================================================
def main():
    """Main function to route to the correct page."""
    render_sidebar_info()
    pages = {
        "Resumen de la Tesis": ThesisSummaryPage("Resumen de la Tesis", ""),
        "Clustering de Demanda": ClusteringPage("Clustering de Demanda", ""),
        "Optimizaci贸n de Ubicaciones": OptimizationPage("Optimizaci贸n de Ubicaciones", ""),
        "Evoluci贸n del Sistema con IA Avanzada": AIEvolutionPage("Evoluci贸n con IA", "")
    }
    selected_page_title = st.sidebar.radio("Seleccione un M贸dulo Anal铆tico:", list(pages.keys()))
    page = pages[selected_page_title]
    page.render()
    render_mathematical_foundations()

if __name__ == "__main__":
    main()
